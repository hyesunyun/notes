# On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? ðŸ¦œ

**Link**: [PDF](https://dl.acm.org/doi/10.1145/3442188.3445922), [Slides](https://docs.google.com/presentation/d/16xC4OsvgVwuOnSn88eOXzzymLEHEFfZod21lLnsXHK0/edit?usp=sharing)  
**Authors**: Emily M. Bender, Timnit Gebru, Angie McMillan-Major, and Shmargaret Shmitchell  
**Conference**: ACM FAccT Conference 2021 (Conference on Fairness, Accountability, and Transparency in Socio-Technical Systems)  
March 3-10, 2021  


## Introduction and Background

> One of the biggest trends in natural language processing (NLP) has been increasing the size of language models (LMs) as measured by the number of parameters and size of the training data.

1. BERT Large (2019) - 340 million parameters, 16 GB dataset size  
2. OpenAI's GPT-3 (2020) - 175 billion parameteres, 570 GB dataset size  
3. Google's GShard (2020) - 600 billion parameters  
4. Google's Switch-C (2021) - 1.6 trillion parameters, 745 GB dataset size  

Questions this paper tries to address:  
1. How big is too big?  
2. What are the possible risks associated with this technology (LMs) and what paths are available for mitigating those risks?  

> We hope that a critical overview of the risks of relying on ever-increasing size of LMs as the primary driver of increased performance of language technology can facilitate a reallocation of efforts towards approaches that avoid some of these risks while still reaping the benefits of improvements to language technology.

Lists already well-documented risks and harms as well as some that are new.

## Costs of Lanaguage Models

### Environmental Costs


### Financial Costs


## Large Training Data

## Stochastic Parrots

## Paths Forward

## Criticism





